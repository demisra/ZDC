{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uproot as ur\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from bitstring import BitArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = []\n",
    "\n",
    "for (path, dirnames, filenames) in os.walk('/mnt/scratch3/dmisra/zdcdata_current/'):\n",
    "    paths.extend(os.path.join(path, name) for name in filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = {}\n",
    "\n",
    "for path in paths:\n",
    "    with ur.open(path) as file:\n",
    "       tree = file[\"events\"]\n",
    "       samples[os.path.basename(f'{path}')] = tree.arrays()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bit Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bitExtract(pattern, length, position):  \n",
    "    return ((1 << length) - 1)  &  (pattern >> (position - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def signedint(xbits):\n",
    "    x_int = []\n",
    "    x_bin = np.vectorize(np.binary_repr, otypes=[str])(xbits, width=12)\n",
    "    for bits in x_bin:\n",
    "        if bits[0] == 0:\n",
    "             x_int.append(BitArray(bin=bits).int)\n",
    "        else:\n",
    "            x_int.append(-BitArray(bin=bits[1:]).int)\n",
    "    return np.array(x_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Energy Deposition per Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "branches = ['ZDC_SiliconPix_Hits', 'ZDC_WSi_Hits', 'ZDC_PbSi_Hits', 'ZDCHcalHits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cell_features(data, count, branch):\n",
    "    event_features = []\n",
    "    energy_labels = []\n",
    "    \n",
    "    for i in range(count):\n",
    "        label = np.sqrt(data[\"MCParticles.momentum.x\"][0,0]**2 + data[\"MCParticles.momentum.y\"][0,0]**2 + data[\"MCParticles.momentum.z\"][0,0]**2)\n",
    "        energy_labels.append(label)\n",
    "        \n",
    "        energies = np.array(data[f\"{branch}.energy\"][i])\n",
    "        cellID = np.array(data[f\"{branch}.cellID\"][i])\n",
    "        layerID = bitExtract(cellID, 6, 9)\n",
    "        idx = signedint(bitExtract(cellID, 11, 25))\n",
    "        idy = signedint(bitExtract(cellID, 11, 37))\n",
    "        \n",
    "        df = pd.DataFrame((zip(idx, idy, layerID, energies)), columns=['idx', 'idy', 'layerID', 'energy'])\n",
    "        df_grouped = df.groupby([\"layerID\", \"idx\", \"idy\"])['energy'].sum().reset_index().replace(np.NaN, 0.)\n",
    "\n",
    "        event_features.append(np.array(df_grouped))\n",
    "        \n",
    "    return event_features, energy_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph Convolutional Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmisra/miniconda3/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch_geometric.data import Data, Dataset, DataLoader\n",
    "from torch_geometric.nn import knn_graph, GCNConv, global_add_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fca0cf48df0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = [np.concatenate(list(samples.values()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_features = cell_features(merged_data[0], 40000, branches[1])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_labels = cell_features(merged_data[0], 40000, branches[1])[1]\n",
    "np.savetxt('/home/dmisra/eic/zdc_data/gnn_labels.csv', data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_labels = np.loadtxt('/home/dmisra/eic/zdc_data/gnn_labels.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.from_numpy(np.array(data_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_set(data):\n",
    "    graph_set = []\n",
    "    for i in range(40000):\n",
    "        tensor = torch.from_numpy(data[i].astype(float))\n",
    "        graph = knn_graph(tensor[:, [0,1,2]], 8)\n",
    "        graph_set.append(graph)\n",
    "\n",
    "    return graph_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "graphs = graph_set(data_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split train/test data\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, num_node_features=4):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        #(3 -> 32)\n",
    "        self.conv1 = GCNConv(num_node_features, 32)\n",
    "        \n",
    "        #(32 -> 1)\n",
    "        self.output = torch.nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        \n",
    "        #add a batch index, in in case we are running on a single graph\n",
    "        if not hasattr(data, \"batch\"):\n",
    "            data.batch = torch.zeros(len(x), dtype=torch.int64).to(x.device)\n",
    "        \n",
    "        #Transform the nodes with the graph convolution\n",
    "        transformed_nodes = self.conv1(x, edge_index)\n",
    "        transformed_nodes = torch.nn.functional.elu(transformed_nodes)\n",
    "        \n",
    "        #Sum up all the node vectors in each graph according to the batch index\n",
    "        per_graph_aggregation = global_add_pool(transformed_nodes, data.batch)\n",
    "        \n",
    "        #For each graph,\n",
    "        #predict the classification output based on the total vector\n",
    "        #from the previous aggregation step\n",
    "        output = self.output(per_graph_aggregation)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model_2.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set number of epochs\n",
    "epochs = 50000\n",
    "\n",
    "#Create lists to track loss values\n",
    "train_loss_values = []\n",
    "test_loss_values = []\n",
    "epoch_count = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    ###Training\n",
    "    net.train()\n",
    "    y_pred = net(x_train)\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    ###Testing\n",
    "    net.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        test_pred = net(x_test)\n",
    "        test_loss = loss_fn(test_pred, y_test.type(torch.float))\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            epoch_count.append(epoch)\n",
    "            train_loss_values.append(loss.detach().numpy())\n",
    "            test_loss_values.append(test_loss.detach().numpy())\n",
    "            print(f\"Epoch: {epoch} | MSE Train Loss: {loss} | MSE Test Loss: {test_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss curves\n",
    "plt.plot(epoch_count, train_loss_values, label=\"Train loss\")\n",
    "plt.plot(epoch_count, test_loss_values, label=\"Test loss\")\n",
    "plt.title(\"Training and Test Loss Curves\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the model in evaluation mode\n",
    "model_1.eval()\n",
    "\n",
    "#Setup the inference mode context manager\n",
    "with torch.inference_mode():\n",
    "  y_preds = model_1(x_test)\n",
    "\n",
    "plt.hist(y_preds[:,0].numpy(),100,histtype='step')\n",
    "plt.xlabel('Energy (GeV)')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Predicted Energy Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the model in evaluation mode\n",
    "model_1.eval()\n",
    "\n",
    "#Setup the inference mode context manager\n",
    "with torch.inference_mode():\n",
    "  y_preds_200GeV = model_1(features_200GeV)\n",
    "  y_preds_100GeV = model_1(features_100GeV)\n",
    "  y_preds_50GeV = model_1(features_50GeV)\n",
    "  y_preds_10GeV = model_1(features_10GeV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_preds = norm.fit(y_preds_10GeV)[0], norm.fit(y_preds_50GeV)[0], norm.fit(y_preds_100GeV)[0], norm.fit(y_preds_200GeV)[0]\n",
    "true_peaks = [10,50,100,200]\n",
    "peak_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(true_peaks,peak_preds)\n",
    "plt.xlabel('Particle Energy (GeV)')\n",
    "plt.ylabel('Reconstructed Energy (GeV)')\n",
    "plt.plot(np.arange(1,201),np.arange(1,201))\n",
    "plt.title('Linearity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get energy resolution from distribution of predictions\n",
    "def res(preds,energy):\n",
    "    return norm.fit(preds)[1]/energy\n",
    "\n",
    "energy_list = [200,100,50,10]\n",
    "resolutions = res(y_preds_200GeV,200), res(y_preds_100GeV,100), res(y_preds_50GeV,50), res(y_preds_10GeV,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Curve fit for energy resolution as a function of energy\n",
    "def f(E,a):\n",
    "    return a/np.sqrt(E)\n",
    "\n",
    "popt, pcov = curve_fit(f, energy_list, resolutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popt, pcov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(200),f(range(1,201),popt[0]))\n",
    "plt.scatter(energy_list,resolutions)\n",
    "plt.xlabel('Energy (GeV)')\n",
    "plt.ylabel('Resolution')\n",
    "plt.title('Energy Resolution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(obj=model_1.state_dict(), f=\"/home/dmisra/eic/model_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "be0ad538c402c22927254208aecd010220eb94d12e6a2da33653e1d12172e2c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
